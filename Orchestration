Container orchestration is all about managing the life cycle of containers, especally in large and dynamic environment.
* provisoning and deployment of containers
* Scaling up or removieng containers
* movement of containers from one host to another
* Load balacing and service discovery between containers
* Health monitoring of containers and hosts
Minimum of 2 web-server should be running all the time
Example. Amazone ECS task placement. its an orchestration tool
Container orchestration Solutions
 * Docker Swarm, kubernetes, Apaches Mesos, AWS ECS
Managed kubernetes like EKS -: since it would be difficult 

-- docker service ls

docker swarm is a container orchestration tool which is natively supported by docker
swarm cluster -: are the collection of the nodes
Node is an instance of the docker engine participating in the swarm
the manager node dispatches units of work called task to the worker node

--- docker swarm init --advertise-addr 'manager ip'
--- ifconfig
---- ifconfig eth0
---- docker swam join --token 'copy and paste the token generated when creating the manager node'
---- docker node ls
when deleting a  node first it have to be demouted

Service -: the defination of the task to execute on the manager or worker nodes

-- docker service create --name webserver --replicas 2 nginx
-- docker service ps webserver

scaling up in swarm
----docker service scale sevice01=1 service03=3
-----docker service update --replicas 1 service2
the difference is with the first one we can scale multiple services at once.

Global vs replicated service
In global service the task is applied over the entire nodes that are present. for example
when installing antivirus use so global so the antivirus will be applied over the entire node.
a global is a single task so no need for replicas
replicated is simple number of nodes that are running the same task.

--- docker service create --name antivirs --mode global -dt ubuntu

Draining a node.
this is needed when a node is to be updated, restarted. you have to move the task to another 
availible node
  -- docker node update --availability drain swarm03
  -- docker node update --availability active swarm03

Inspect swarm and services
-- docker service ps 'service name'
-- docker service inspect 'service name'
-- docker service inspect 'service name' --pretty
-- docker node inspect 'node name'
-- docker node inspect 'node name' --pretty

 publising ports on the swarm
if the port is not published there would be no way to access the container from the outside so it
need to be publised when creating the service
netstat -ntlp
docker service create --name mywebserver --replicas 2 --publish 8080:80 nginx
ifconfig eth0
curl 172.18.19.160:8080

Docker compose
used when containers have dependencies on other containers
use yaml file to put it togather
--- docker-compose up 'container names'
--- docker-compose down 'container name'
--- docker-compose config  -: check if the syntax is correct
--- docker-compose version
if no container name is given it wil either start all the containes in the docker-compose file
or stop them
docke compose come togather in windows but in lunix you have to download it

Deploying multi service apps in swarm
Containers that have dependencies with other containers so we can use the docker stack
A stack is a group of interrelated services that share dependencies and can be orchestrated and
scaled together
it can compose YAML file like docker compose

-- docker stack deploy --compose-file docker-compose.yml mydemo

Locking swarm cluster
in the cd /var/lab/docker, you can find all the keys there so you have to use the lock feture
--- docker swarm update --help
--- docker swarm update --autolock=true
 SWMKEY-1-9g2WqHql/XH0QmIjCo3bw9VzKV9nG2vRvGHR0fyMtII
--- docker swarm unlock
--- docker swarm unlock-key   to retrive the key
--- docker swarm unlock-ky --rotate
 SWMKEY-1-ZsOw5CbfOMXzAa6ZpvWqqNXfe7t2HUA6vMjZxSrLjIc

Troubelshoot Service Deployments
scenarios can be 1. no node can persform the task of the service. 2. all nodes are drained
3. you reserve specific amount of memory and so on for the service and you dont't have the
resourse specified. 4. some kind of placement constrain
this can lead a service to be on pending state

--- docker inspect 'id of the thing to be inspected'
a json file will be produced and you can see at the status part if there is error and so on.

applying constrains to the service with 
-- docker service create --name troubleshoot --constraint=node.labels.region==1oslo --replicas 3 nginx

Mounting volums in swarm

-- docker service create --name myservice --mount type=volume,source=myvolume,target=/mypath nginx
-- docker container exec -it 'container id' bash
 ls -l / to see mypath that is specified when creating the service
cd /mypath/    enter the mypath folder
touch test.txt   create a file called test.txt
-- docker volume ls
cd /var/lib/docker/volumes/   go in to the volumes that ares created
if the container fail since the volume is used as storage the date wont be lost
even if you remove the service the volume will still be there.

control service placement
there are different ways fou you to control the scale and placement of services on different nodes
1. replicated and global service, 2. Resourse constaint(cpu etc) 3. placement contrainct(only runs
on node with label pci_compliance=true) 4. placement preferences
-- docker node update --label-add region=oslo 'node id'
-- --docker service create --name myconstraint --constraint node.labels.region==oslo --replicas 3 nginx
-- docker node inspect 'node id' -: heare we can find the label to apply on the node.label.region

 Overlya networks
it is the way containers in a dristributed network communicate.
The overlay network driver creates a distrbiuted network among multiple docker daemon hosts
overlay network allows containers connected to it to communicate securly
it connects nodes in a swarm. when ever you create a swarm with nodes the overlay driver is
by default translated

-- docker network ls
-- docker network inspect 'network name or id'
on the out put there is peers which show all the ip and names of the nodes
we can ping from the one node to another by using the ip address. this is because the overly
have made it possible to connect securly

--ping 172.18.19.160 

-- docker network create --driver overlay mynetwork
-- docker service create --name overlayservice --network mynetwork --replicas 3 nginx
